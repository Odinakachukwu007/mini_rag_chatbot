{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7347c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\prosp\\onedrive - ensign college\\documents\\ai_intern_projects\\env\\lib\\site-packages (2.32.4)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\prosp\\onedrive - ensign college\\documents\\ai_intern_projects\\env\\lib\\site-packages (4.13.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\prosp\\onedrive - ensign college\\documents\\ai_intern_projects\\env\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\prosp\\onedrive - ensign college\\documents\\ai_intern_projects\\env\\lib\\site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\prosp\\onedrive - ensign college\\documents\\ai_intern_projects\\env\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prosp\\onedrive - ensign college\\documents\\ai_intern_projects\\env\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prosp\\onedrive - ensign college\\documents\\ai_intern_projects\\env\\lib\\site-packages (from requests) (2025.7.9)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\prosp\\onedrive - ensign college\\documents\\ai_intern_projects\\env\\lib\\site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\prosp\\onedrive - ensign college\\documents\\ai_intern_projects\\env\\lib\\site-packages (from beautifulsoup4) (4.14.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\prosp\\onedrive - ensign college\\documents\\ai_intern_projects\\env\\lib\\site-packages (from pandas) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\prosp\\onedrive - ensign college\\documents\\ai_intern_projects\\env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\prosp\\onedrive - ensign college\\documents\\ai_intern_projects\\env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\prosp\\onedrive - ensign college\\documents\\ai_intern_projects\\env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prosp\\onedrive - ensign college\\documents\\ai_intern_projects\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a767af1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: https://www.churchofjesuschrist.org/study/general-conference/2025/04/41bednar?lang=eng\n",
      "Scraping: https://www.churchofjesuschrist.org/study/general-conference/2025/04/47oaks?lang=eng\n",
      "Scraping: https://www.churchofjesuschrist.org/study/general-conference/2025/04/57nelson?lang=eng\n",
      "Scraping: https://www.churchofjesuschrist.org/study/general-conference/2025/04/13holland?lang=eng\n",
      "Scraping: https://www.churchofjesuschrist.org/study/general-conference/2025/04/18eyring?lang=eng\n",
      "Scraping: https://www.churchofjesuschrist.org/study/general-conference/2025/04/27uchtdorf?lang=eng\n",
      "\n",
      "✅ Total talks scraped: 6\n",
      "                                               title  \\\n",
      "0             The Times of Restitution of All Things   \n",
      "1                         Divine Helps for Mortality   \n",
      "2                  Confidence in the Presence of God   \n",
      "3                                  As a Little Child   \n",
      "4                                “Draw Near unto Me”   \n",
      "5  “By This All Will Know That You Are My Disciples”   \n",
      "\n",
      "                           speaker  \\\n",
      "0         By Elder David A. Bednar   \n",
      "1      By President Dallin H. Oaks   \n",
      "2   By President Russell M. Nelson   \n",
      "3  By President Jeffrey R. Holland   \n",
      "4     By President Henry B. Eyring   \n",
      "5      By Elder Dieter F. Uchtdorf   \n",
      "\n",
      "                                        speaker_role  \\\n",
      "0               Of the Quorum of the Twelve Apostles   \n",
      "1            First Counselor in the First Presidency   \n",
      "2  President of The Church of Jesus Christ of Lat...   \n",
      "3  Acting President of the Quorum of the Twelve A...   \n",
      "4           Second Counselor in the First Presidency   \n",
      "5               Of the Quorum of the Twelve Apostles   \n",
      "\n",
      "                                             content  \\\n",
      "0  The Church of Jesus Christ of Latter-day Saint...   \n",
      "1  Through the Prophet Joseph Smith, the Lord rev...   \n",
      "2  My dear brothers and sisters, I am grateful to...   \n",
      "3  Jesus began the last year of His mortal life b...   \n",
      "4  My dear brothers and sisters, it is a joy for ...   \n",
      "5  Many years ago Sister Uchtdorf and I were trav...   \n",
      "\n",
      "                                              source  \n",
      "0  https://www.churchofjesuschrist.org/study/gene...  \n",
      "1  https://www.churchofjesuschrist.org/study/gene...  \n",
      "2  https://www.churchofjesuschrist.org/study/gene...  \n",
      "3  https://www.churchofjesuschrist.org/study/gene...  \n",
      "4  https://www.churchofjesuschrist.org/study/gene...  \n",
      "5  https://www.churchofjesuschrist.org/study/gene...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Paste your list of 6 talk URLs here\n",
    "talk_urls = [\n",
    "    \"https://www.churchofjesuschrist.org/study/general-conference/2025/04/41bednar?lang=eng\",\n",
    "    \"https://www.churchofjesuschrist.org/study/general-conference/2025/04/47oaks?lang=eng\",\n",
    "    \"https://www.churchofjesuschrist.org/study/general-conference/2025/04/57nelson?lang=eng\",\n",
    "    \"https://www.churchofjesuschrist.org/study/general-conference/2025/04/13holland?lang=eng\",\n",
    "    \"https://www.churchofjesuschrist.org/study/general-conference/2025/04/18eyring?lang=eng\",\n",
    "    \"https://www.churchofjesuschrist.org/study/general-conference/2025/04/27uchtdorf?lang=eng\"\n",
    "]\n",
    "\n",
    "# Step 2: Initialize data lists\n",
    "titles = []\n",
    "speakers = []\n",
    "roles = []\n",
    "contents = []\n",
    "sources = []\n",
    "\n",
    "# Step 3: Loop through each URL\n",
    "for url in talk_urls:\n",
    "    print(\"Scraping:\", url)\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Get title\n",
    "        meta_title = soup.find('meta', property='og:title')\n",
    "        title = meta_title['content'] if meta_title else 'N/A'\n",
    "\n",
    "        # Get speaker\n",
    "        speaker_tag = soup.find('p', class_='author-name')\n",
    "        speaker = speaker_tag.get_text(strip=True) if speaker_tag else 'N/A'\n",
    "\n",
    "        # Get speaker role\n",
    "        role_tag = soup.find('p', class_='author-role')\n",
    "        role = role_tag.get_text(strip=True) if role_tag else 'N/A'\n",
    "\n",
    "        # Get content\n",
    "        content_div = soup.find('div', class_='body-block')\n",
    "        paragraphs = content_div.find_all('p') if content_div else []\n",
    "        content = '\\n'.join(p.get_text(strip=True) for p in paragraphs)\n",
    "\n",
    "        # Final check: If any required field is missing, we still record the data but mark what's missing\n",
    "        if not content:\n",
    "            print(\"⚠️ Warning: Content not found for\", url)\n",
    "\n",
    "        # Append all scraped fields to respective lists\n",
    "        titles.append(title)\n",
    "        speakers.append(speaker)\n",
    "        roles.append(role)\n",
    "        contents.append(content)\n",
    "        sources.append(url)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error scraping {url}: {e}\")\n",
    "        # Fill missing entry with \"N/A\" so index alignment stays correct\n",
    "        titles.append(\"N/A\")\n",
    "        speakers.append(\"N/A\")\n",
    "        roles.append(\"N/A\")\n",
    "        contents.append(\"N/A\")\n",
    "        sources.append(url)\n",
    "\n",
    "# Step 4: Build the DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'title': titles,\n",
    "    'speaker': speakers,\n",
    "    'speaker_role': roles,\n",
    "    'content': contents,\n",
    "    'source': sources\n",
    "})\n",
    "\n",
    "# Step 5: Display the DataFrame shape and preview\n",
    "print(\"\\n✅ Total talks scraped:\", df.shape[0])\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8ae2f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File saved successfully to Data/general_conference_talks.csv\n"
     ]
    }
   ],
   "source": [
    "# Save scraped data to CSV\n",
    "df.to_csv(\"Data/general_conference_talks.csv\", index=False)\n",
    "print(\"✅ File saved successfully to Data/general_conference_talks.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
